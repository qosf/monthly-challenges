{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "657b2d49",
   "metadata": {
    "id": "657b2d49"
   },
   "source": [
    "# Challenge 08: k-Nearest Neighbors\n",
    "\n",
    "**_This challenge is brought to you by [@MaldoAlberto](https://github.com/MaldoAlberto) as a community contribution. Thank you!_**\n",
    "\n",
    "The k-Nearest Neighbors (k-NN) algorithm is one of the best known classification algorithms and an example of [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning). The objective of a classification algorithm is to identify correctly which class a data point belongs to. The training data used to train this algorithm includes labels (e.g. \"1\", \"2\", \"dog\", \"cat\", etc.) already. The k in k-NN is the number of nearest neighbors that we are going to compare a data point to in order to choose which class it belongs, therefore this classifier will consider the test set that we will call states $|a_i>$ whose labels are determined by finding the minimum distance to the states of the training set $|b_j>$, whose labels are known beforehand [[1]](https://arxiv.org/pdf/2003.09187.pdf). \n",
    "\n",
    "![k-NN example](knn.png)\n",
    "\n",
    "Figure 1. Example of a k-NN with k=3. (image obtained from [here](https://github.com/artifabrian/dynamic-knn-gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fI7bt50CjF9M",
   "metadata": {
    "id": "fI7bt50CjF9M"
   },
   "source": [
    "To find the distance between two instances, in classical computation one of these is the Euclidean distance, $\\lvert a-b \\rvert = \\sqrt{\\sum_{i=1}^N (a_i-b_i)^2}$. In the case of quantum computation, its equivalence is achieved from the inner product (or dot product) which is defined as $\\lvert a-b \\rvert = \\lvert a \\rvert  \\lvert b \\rvert -a \\cdot b$, where |a> and |b> are two quantum states. To implement the inner product corresponding to the Euclidean distance, it is necessary to use a quantum subroutine known as the SWAP test [[2]](https://arxiv.org/pdf/1401.2142.pdf), which is a quantum algorithm that can be used to estimate the fidelity of two pure states $|\\phi>$ and $|\\psi>$, i.e., $F=\\lvert<\\psi|\\phi>\\rvert ^2$. Figure (2) shows the quantum circuit to perform such an operation:\n",
    "\n",
    "![swap test](swap_t.png)\n",
    "\n",
    "The measurement of the first qubit in the quantum circuit will indicate the following probability:\n",
    "\n",
    "$P(q_0 = 0) =\\frac{1}{2}+\\frac{1}{2}\\lvert<\\psi|\\phi>\\rvert^2  $\n",
    "\n",
    "If the two states are orthogonal, then the probability will be $\\frac{1}{2}$ and if they match, then the probability will be $1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2401dba9-aa5e-4a30-9c53-0a0e2d537dfa",
   "metadata": {},
   "source": [
    "### The Challenge\n",
    "\n",
    "**Task 1**  \n",
    "Design a quantum circuit to perform k-NN classification using only two classes of your preference (for example classes \"3\", \"7\") from the MNIST dataset. Test your classifier using the following values of k: 1,3,5,7. With this being a binary classification, use odd values to break a tie to which class it belongs (similar to the [Pigeonhole principle](https://en.wikipedia.org/wiki/Pigeonhole_principle)). Achieve classification with at least 85% accuracy.\n",
    "\n",
    "How to  obtain the MNIST dataset:  \n",
    "https://www.tensorflow.org/tutorials/quickstart/beginner  \n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html  \n",
    "https://csc.lsu.edu/~saikat/n-mnist/  \n",
    "\n",
    "**Task 2**  \n",
    "Try solving the problem with a decreased number of qubits for holding the image information (using a classical [[3]](https://arxiv.org/pdf/1908.02626.pdf),[[4]](https://arxiv.org/pdf/1404.1100.pdf),[[5]](https://www.mdpi.com/2504-3900/54/1/40/pdf) preprocessing step) or using the idea of [Challenge-05](https://github.com/qosf/monthly-challenges/tree/main/challenge-05). \n",
    "\n",
    "**Task 3 (Bonus)**  \n",
    "Increase the challenge to include a third class, such as using classes \"0\", \"7\" and \"8\" with an accuracy of at least 85%. Having more than two classes I considered this [post](https://towardsdatascience.com/a-simple-introduction-to-k-nearest-neighbors-algorithm-b3519ed98e) to identify the value of k that would be the best for the classification. What about a fourth class? How high can you go?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2f283",
   "metadata": {
    "id": "bcb2f283"
   },
   "source": [
    "### References\n",
    "\n",
    "[1] Afham, & Basheer, Afrad & Goyal, Sandeep. (2020). Quantum k-nearest neighbor machine learning algorithm. \n",
    "\n",
    "[2] Wiebe, Nathan & Kapoor, Ashish & Svore, Krysta. (2015). Quantum algorithms for nearest-neighbor methods for supervised and unsupervised learning. Quantum Information and Computation. 15. 318-358. \n",
    "\n",
    "### Resources\n",
    "\n",
    "[3] Rudolph, Marco & Wandt, Bastian & Rosenhahn, Bodo. (2019). Structuring Autoencoders. \n",
    "\n",
    "[4] Shlens, Jonathon. (2014). A Tutorial on Principal Component Analysis. Educational. 51. \n",
    "\n",
    "[5] Figueira-Domínguez, J.G.; Bolón-Canedo, V.; Remeseiro, B. Feature Selection in Big Image Datasets. Proceedings 2020, 54, 40. https://doi.org/10.3390/proceedings2020054040\n",
    "\n",
    "[6] Ruan, Yue & Xue, Xiling & Liu, Heng & Tan, Jianing & Li, Xi. (2017). Quantum Algorithm for K-Nearest Neighbors Classification Based on the Metric of Hamming Distance. International Journal of Theoretical Physics. 56. 10.1007/s10773-017-3514-4. \n",
    "\n",
    "[7] Giovannetti, Vittorio & Lloyd, Seth & Maccone, Lorenzo. (2008). Quantum Random Access Memory. Physical review letters. 100. 160501. 10.1103/PhysRevLett.100.160501. \n",
    "\n",
    "[8] Toghi, Behrad & Grover, Divas. (2018). MNIST Dataset Classification Utilizing k-NN Classifier with Modified Sliding Window Metric. \n",
    "\n",
    "[9] Katyayan, Pragya & Joshi, Nisheeth. (2020). Quantum Computing: Start your journey with Qiskit! | Open Source for You (December 2020). 10.13140/RG.2.2.32232.08961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1fc10-de38-451b-ac54-74265854938d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "qosf-monthly-challenge-07.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
